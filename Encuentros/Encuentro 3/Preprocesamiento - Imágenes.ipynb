{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizaje automático y aplicaciones\n",
    "\n",
    "---\n",
    "$A^3$ @ FI-UNER : 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color:#FFFFAA;padding:10px'>\n",
    "<h1 style='color:#000000'><b>Preprocesamiento de imágenes</b></h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Librerías</h2>\n",
    "\n",
    "<!--\n",
    "- Lectura de datos\n",
    "- RGB -> GRAY\n",
    "- Estandarizar imagenes (resize, crop, etc)\n",
    "- Remoción del fondo, para reducir el ruido.\n",
    "- Cambiar brillo/contraste.\n",
    "-->\n",
    "\n",
    "- <h4><a href=\"#PIL\"><b style=\"color:#51B91A\">PIL (Pillow)</b></a></h4>\n",
    "- <h4><a href=\"#skimage\"><b style=\"color:#51B91A\">skimage</b></a></h4>\n",
    "- <h4><a href=\"#cv2\"><b style=\"color:#51B91A\">cv2 (OpenCV)</b></a></h4>\n",
    "\n",
    "\n",
    "<!--\n",
    "- <h5><a href=\"#PIL\"><b style=\"color:#51B91A\">Lectura de datos</b></a></h5>\n",
    "- <h5><a href=\"#PIL\"><b style=\"color:#51B91A\">PIL (Pillow)</b></a></h5>\n",
    "- <h5><a href=\"#PIL\"><b style=\"color:#51B91A\">PIL (Pillow)</b></a></h5>\n",
    "\n",
    "<h4><a href=\"#Lectura-de-datos\">- <b style=\"color:#51B91A\">Lectura de datos</b></a></h4>\n",
    "<h4><a href=\"#Análisis-exploratorio\">- <b style=\"color:#51B91A\">Análisis exploratorio</b></a></h4>\n",
    "<h4><a href=\"#Corrección de tipos de datos\">- <b style=\"color:#51B91A\">Corrección de tipos de datos</b></a></h4>\n",
    "<h4><a href=\"#Manejo-de-datos-faltantes\">- <b style=\"color:#51B91A\">Manejo de datos faltantes</b></a></h4>\n",
    "<h4><a href=\"#Transformación-de-datos\">- <b style=\"color:#51B91A\">Transformación de datos</b></a></h4>\n",
    "<h4><a href=\"#Nuevos datos\">- <b style=\"color:#51B91A\">Nuevos datos</b></a></h4>\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color:#FFFFAA;padding:10px'>\n",
    "<h2 style='color:#000000'><b>Lectura de datos</b></h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LECTURA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(\"gato.jpg\")  # --> RGB\n",
    "print(type(im))\n",
    "im\n",
    "#im.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONVERSION A NUMPY-ARRAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = np.asarray(im)\n",
    "\n",
    "print(type(ar))\n",
    "\n",
    "s = ar.copy()\n",
    "\n",
    "s[:,:,1] = s[:,:,0]\n",
    "s[:,:,2] = s[:,:,0]\n",
    "\n",
    "im2 = Image.fromarray(s[:,:,0])\n",
    "im2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RGB --> GRAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im3 = im.convert('LA')\n",
    "im3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im.resize(size=(224,224), resample=Image.NEAREST).convert('LA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CROPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im4 = im.crop((250,150,600,500))  # (left, upper, right, lower)-tuple.\n",
    "im4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INFORMACION DE LA IMAGEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(im.getbands())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im.getbbox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im.getchannel('R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZACION DEL HISTOGRAMA PARA EL CANAL \"G\"\n",
    "plt.plot(im.getchannel('G').histogram());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EQUALIZACION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_a = im.resize(size=(300,300))\n",
    "im_b = ImageOps.equalize(im).resize(size=(300,300))\n",
    "im_c = ImageOps.autocontrast(im).resize(size=(300,300))\n",
    "\n",
    "im_b = np.asarray(im_b)\n",
    "im_c = np.asarray(im_c)\n",
    "\n",
    "fig,ax = plt.subplots(1, 3, figsize=(20,10))\n",
    "ax[0].imshow(im_a)\n",
    "ax[1].imshow(im_b)\n",
    "ax[2].imshow(im_c);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage as ski\n",
    "import skimage.io as io\n",
    "from skimage import data, color, exposure\n",
    "from skimage.transform import rescale, resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LECTURA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = io.imread('gato.jpg')  # --> RGB\n",
    "print(type(im))\n",
    "plt.imshow(im);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RGB --> GRAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = color.rgb2gray(im)\n",
    "\n",
    "#print(im.shape)\n",
    "#print(image.shape)\n",
    "\n",
    "#image = ski.util.img_as_ubyte(image)  # float --> INT8\n",
    "#print(image)\n",
    "\n",
    "plt.imshow(image, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_resized = resize(image,\n",
    "                       (image.shape[0] // 10,\n",
    "                        image.shape[1] // 10),\n",
    "                       anti_aliasing=True)\n",
    "\n",
    "image_resized = ski.util.img_as_ubyte(image_resized)  # float --> INT8\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(20,10))\n",
    "ax[0].imshow(im);\n",
    "ax[1].imshow(image_resized, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CROP\n",
    "image_cropped = im[100:-100,200:-200]  # --> numpy.ndarray\n",
    "plt.imshow(color.rgb2gray(image_cropped), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAMMA CORRECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_corrected = exposure.adjust_gamma(im, 2)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(20,10))\n",
    "ax[0].imshow(im)\n",
    "ax[1].imshow(gamma_corrected);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOGARITHMIC CORRECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logarithmic_corrected = exposure.adjust_log(im, 1)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(20,10))\n",
    "ax[0].imshow(im)\n",
    "ax[1].imshow(logarithmic_corrected);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONTRAST STRECHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2, p98 = np.percentile(im, (2, 98))\n",
    "img_rescale = exposure.rescale_intensity(im, in_range=(p2, p98))\n",
    "\n",
    "# Equalization\n",
    "img_eq = exposure.equalize_hist(im)\n",
    "\n",
    "# Adaptive Equalization\n",
    "img_adapteq = exposure.equalize_adapthist(im, clip_limit=0.03)  # --> CLAHE\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(20,10))\n",
    "ax[0].imshow(im)\n",
    "ax[0].set_title('Original')\n",
    "\n",
    "ax[1].imshow(img_rescale)\n",
    "ax[1].set_title('Contrast stretching')\n",
    "\n",
    "ax[2].imshow(img_eq)\n",
    "ax[2].set_title('Histogram equalization')\n",
    "\n",
    "ax[3].imshow(img_adapteq)\n",
    "ax[3].set_title('Adaptive equalization');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LECTURA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv.imread('gato.jpg')  # --> BGR\n",
    "\n",
    "print(type(im))\n",
    "\n",
    "#im2 = np.zeros_like(im)\n",
    "#im2[:,:,0] = im[:,:,2]\n",
    "#im2[:,:,1] = im[:,:,1]\n",
    "#im2[:,:,2] = im[:,:,0]\n",
    "\n",
    "#im2 = im[:,:,::-1]\n",
    "\n",
    "#plt.imshow(im2)\n",
    "\n",
    "## SHOW WITH OPENCV\n",
    "#cv.imshow(\"Original image\", im)\n",
    "#cv.waitKey(0)\n",
    "#cv.destroyAllWindows()\n",
    "\n",
    "## SHOW WITH MATPLOTLIB\n",
    "#plt.imshow(im);\n",
    "#plt.imshow(cv.cvtColor(im, cv.COLOR_RGB2BGR));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RGB --> GRAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv.cvtColor(im, cv.COLOR_RGB2GRAY), cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized = cv.resize(im,\n",
    "                    (224,224),\n",
    "                    interpolation=cv.INTER_AREA)\n",
    "\n",
    "plt.imshow(cv.cvtColor(resized, cv.COLOR_RGB2GRAY), cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CROPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_cropped = im[150:-150,150:-150]\n",
    "plt.imshow(cv.cvtColor(im_cropped, cv.COLOR_RGB2BGR));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EQUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_equ = cv.equalizeHist(im[:,:,0])\n",
    "\n",
    "# CLAHE\n",
    "clahe = cv.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "im_clahe = clahe.apply(im[:,:,0])\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,3,figsize=(20,10))\n",
    "ax[0].imshow(im[:,:,0], cmap='gray')\n",
    "ax[1].imshow(im_equ, cmap='gray')\n",
    "ax[2].imshow(im_clahe, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FILTRADO DE RUIDO SAL Y PIMIENTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addsalt_pepper(img, SNR=1.0):\n",
    "    \n",
    "    img_ = img.copy()\n",
    "    img_ = img_.transpose(2, 1, 0)\n",
    "    c, h, w = img_.shape\n",
    "    mask = np.random.choice((0, 1, 2), size=(1, h, w), p=[SNR, (1 - SNR) / 2., (1 - SNR) / 2.])\n",
    "    Mask = np.repeat(mask, c, axis=0) # Copy by channel to have the same shape as img\n",
    "    img_[Mask == 1] = 255 # salt noise\n",
    "    img_[Mask == 2] = 0 # \n",
    "    \n",
    "    img_ = img_.transpose(2, 1, 0)\n",
    "    \n",
    "    return img_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILTRADO\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('gato.jpg', 1)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "noise = addsalt_pepper(img, SNR=0.7)\n",
    "\n",
    "\n",
    "# FILTRADO\n",
    "median_blur= cv2.medianBlur(noise, 5)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3,figsize=(20,10))\n",
    "\n",
    "ax[0].imshow(img)\n",
    "ax[1].imshow(noise)\n",
    "ax[2].imshow(median_blur);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
