{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"MLP con PyTorch.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.2"}},"cells":[{"cell_type":"markdown","metadata":{"id":"cDxrnfQW6k4l"},"source":["## Carga de bibliotecas"]},{"cell_type":"code","metadata":{"id":"6RheZEhn0huB"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","import torch\n","from torch import nn\n","from torch import optim\n","from torch.utils.data import Dataset, DataLoader\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # Utilizará GPU si está disponible"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vqBr5IvfRkzd"},"source":["# Construcción del dataset"]},{"cell_type":"code","metadata":{"id":"ciB4E-qlRkze"},"source":["class ConcentDataset(Dataset):\n","    \n","    #=====================================================\n","    def __init__(self, filename=None, transform=None, target_transform=None):\n","        \n","        \n","        data = pd.read_csv(filename)  # Reading data\n","        \n","        patterns = data.iloc[:,:-1].to_numpy()  # Extracting patterns and transforming to numpy\n","        labels = data.iloc[:,-1].to_numpy()  # Extracting labels and transforming to numpy\n","        labels[labels==-1] = 0  #  Replace \"-1\" labels with \"0\" (sigmoid function works in [0,1] range)\n","        \n","        self.patterns = torch.from_numpy(patterns).type(torch.FloatTensor)  # Transforming to torch\n","        self.labels = torch.from_numpy(labels).type(torch.FloatTensor)  # Transforming to torch\n","        \n","        self.transform = transform\n","        self.target_transform = target_transform\n","    \n","    #=====================================================\n","    def __len__(self):\n","        \n","        return len(self.labels)\n","    \n","    \n","    #=====================================================\n","    def __getitem__(self, idx):\n","        \n","        pattern = self.patterns[idx,:]  # Get pattern \"idx\"\n","        label = self.labels[idx]  # Get label for pattern \"idx\"\n","        \n","        #--------------------------------------\n","        if self.transform:\n","            pass\n","        if self.target_transform:\n","            pass\n","        #--------------------------------------\n","        \n","        return pattern, label"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cosvtBmyxTjc"},"source":["# Carga de los datasets"]},{"cell_type":"code","metadata":{"id":"BvAtBDgqRkzi"},"source":["# CARGO DATASETS\n","\n","train_data = ConcentDataset(filename='concent_train.csv')\n","val_data = ConcentDataset(filename='concent_valid.csv')\n","test_data = ConcentDataset(filename='concent_test.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GY2L6Ki5Rkzj"},"source":["# GRAFICO PATRONES\n","\n","fig,ax = plt.subplots(1, 3, figsize=(21,7))\n","\n","for i in range(3):\n","    \n","    if i == 0:\n","        X = train_data.patterns\n","        Y = train_data.labels\n","        title = 'Train data'\n","    if i == 1:\n","        X = val_data.patterns\n","        Y = val_data.labels\n","        title = 'Validation data'\n","    if i == 2:\n","        X = test_data.patterns\n","        Y = test_data.labels\n","        title = 'Test data'\n","    \n","    colors = [f'C{int(y)}' for y in Y]\n","    \n","    ax[i].scatter(X[Y==0,0], X[Y==0,1], 30, c='b', label='Clase 0')\n","    ax[i].scatter(X[Y==1,0], X[Y==1,1], 30, c='y', label='Clase 1')\n","    \n","    ax[i].set_title(title)\n","    ax[i].set_xlabel(u'$X_{1}$', fontsize=14)\n","    ax[i].set_ylabel(u'$X_{2}$', fontsize=14)\n","    ax[i].grid(True)\n","    ax[i].legend(loc='best')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Lz7FlCRNRkzn"},"source":["# Construcción del dataloader"]},{"cell_type":"code","metadata":{"id":"zptOpa4gRkzr"},"source":["train_dataloader = DataLoader(train_data, batch_size=16, shuffle=True)\n","val_dataloader = DataLoader(val_data, batch_size=16, shuffle=True)\n","test_dataloader = DataLoader(test_data, batch_size=16, shuffle=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CskXs_8a6k5L"},"source":["# Construcción del modelo neuronal"]},{"cell_type":"code","metadata":{"id":"0TXEJmp-Y-P0"},"source":["class MLP_desglosado(nn.Module):\n","    '''\n","    MLP con 2 capas: Entrada, salida.\n","    Este modelo explicita el flujo de información a través de la red.\n","    \n","    '''\n","    \n","    #===========================\n","    def __init__(self, n_inputs=2, layer1=3, n_outputs=1):\n","        \n","        super(MLP_desglosado, self).__init__()\n","        \n","        #===========================\n","        #BLOQUES DE CONSTRUCCION\n","        #===========================\n","        self.layer1 = nn.Linear(n_inputs, layer1, bias=True)  # ENTRADA: Inputs [features] --> neuronas_layer1\n","        self.layer2 = nn.Linear(layer1, n_outputs, bias=True)  # SALIDA: neuronas_layer2   --> Outputs [clases]\n","        self.sigmoid = nn.Sigmoid()  # Función de transferencia\n","    \n","    \n","    #===========================\n","    def forward(self, x):\n","        \n","        # CAPA 1\n","        y = self.layer1(x)  # Salida lineal\n","        y = self.sigmoid(y)  # Función no lineal\n","        \n","        # CAPA 2\n","        y = self.layer2(y)  # Salida lineal\n","        y = self.sigmoid(y)  # Función no lineal\n","        \n","        return y  # salida de la red"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eFekPlSBxTjm"},"source":["class MLP_bloque(nn.Module):\n","    '''\n","    MLP con 2 capas: Entrada, salida.\n","    Este modelo es equivalente al anterior. La diferencia está en que genera\n","    un \"bloque\" de procesamiento que puede ejecutarse como un único elemento.\n","    \n","    '''\n","    \n","    #===========================\n","    def __init__(self, n_inputs=2, layer1=3, n_outputs=1):\n","        \n","        super(MLP_bloque, self).__init__()\n","        \n","        self.net = nn.Sequential(nn.Linear(n_inputs, layer1, bias=True), # ENTRADA: Inputs [features] --> neuronas_layer1\n","                                 nn.Sigmoid(),  # Función de transferencia\n","                                 nn.Linear(layer1, n_outputs, bias=True), # SALIDA: neuronas_layer2   --> Outputs [clases]\n","                                 nn.Sigmoid()  # Función de transferencia\n","                                )\n","    \n","    \n","    #===========================\n","    def forward(self, x):\n","        \n","        y = self.net(x)\n","        \n","        return y  # salida de la red"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"smmEQ9I8Rkz3"},"source":["# Pasos generales del entrenamiento"]},{"cell_type":"code","metadata":{"id":"zpj9Dt9AxTjq"},"source":["def train_step(model, dataloader, loss_criterion, device):\n","    \n","    model.train()  # Calcula gradientes\n","    \n","    cummulated_loss = 0\n","    \n","    for idx,(X,y) in enumerate(dataloader):\n","\n","        #-----------------------------------------------------\n","        # Convierto los datos en tensores diferenciables\n","        #-----------------------------------------------------\n","        X = X.to(device)\n","        y = y.to(device)\n","\n","        optimizer.zero_grad()  # Se limpia el caché del optimizador\n","        \n","        #----------------\n","        # Forward pass\n","        #----------------\n","        y_pred = model(X)\n","\n","        #----------------\n","        # Compute Loss\n","        #----------------\n","        loss = loss_criterion(y_pred.squeeze(), y)\n","        \n","        cummulated_loss += loss.item()\n","        \n","        #----------------\n","        # Backward pass\n","        #----------------\n","        loss.backward()\n","        optimizer.step()\n","        \n","    #------------------------------------\n","    \n","    N_batches = idx+1  # numero batches, comenzando en 1\n","    cummulated_loss /= N_batches\n","    \n","    return cummulated_loss, model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q6l8xlzWxTjr"},"source":["def predict_step(model, dataloader, loss_criterion, device):\n","    \n","    model.eval()  # No calcula gradientes\n","    \n","    cummulated_loss = 0\n","    \n","    Y = torch.tensor([])\n","    Yp = torch.tensor([])\n","    \n","    for idx,(X,y) in enumerate(dataloader):\n","        \n","        Y = torch.hstack( (Y,y.flatten()) )\n","        \n","        #-----------------------------------------------------\n","        # Convierto los datos en tensores diferenciables\n","        #-----------------------------------------------------\n","        X = X.to(device)\n","        y = y.to(device)\n","        \n","        #----------------\n","        # Forward pass\n","        #----------------\n","        y_pred = model(X)\n","        \n","        Yp = torch.hstack( (Yp, y_pred.cpu().squeeze()) )\n","\n","        #----------------\n","        # Compute Loss\n","        #----------------\n","        loss = loss_criterion(y_pred.squeeze(), y)\n","        \n","        cummulated_loss += loss.item()\n","    \n","    \n","    N_batches = idx+1  # numero batches, comenzando en 1\n","    cummulated_loss /= N_batches\n","    \n","    #------------------\n","    # UMBRAL\n","    #------------------\n","    umbral = 0.5\n","    \n","    Yp[Yp<umbral] = 0\n","    Yp[Yp >= umbral] = 1\n","    \n","    Acc = torch.sum(Yp == Y)/ len(Y)\n","    \n","    #------------------\n","    \n","    return cummulated_loss, Acc"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SE58TJ74xTju"},"source":["## ENTRENAMIENTO"]},{"cell_type":"code","metadata":{"id":"QUGhCvEeY-P6"},"source":["# INICIALIZO MODELO\n","model = MLP_desglosado()\n","#model = MLP_bloque()\n","\n","model.to(device)\n","\n","\n","# DEFINO ESTRUCTURA PARA GUARDAR MEDIDAS\n","measures = {\n","            'trn_loss': [],\n","            'trn_acc': [],\n","            'val_loss': [],\n","            'val_acc': []\n","           }\n","\n","\n","#-------------------------------------------------------\n","# Definimos el criterio de error (métrica a minimizar)\n","# y trasladamos al device [CPU|GPU]\n","#-------------------------------------------------------\n","loss_criterion = nn.MSELoss(reduction='mean').to(device)\n","\n","#-------------------------------------\n","# Definimos el optimizador a utilizar\n","#-------------------------------------\n","optimizer = optim.SGD(model.parameters(), lr=5e-2, momentum=0.9)\n","#optimizer = optim.Adam(model.parameters(), lr=5e-2)\n","\n","# DEFINIMOS PARAMETROS\n","best_loss = 1E6\n","best_model = model.state_dict()\n","best_epoch = 0\n","counter = 0\n","\n","MAX_EPOCHS = 1000  # DEFINIMOS MAXIMO DE EPOCAS DE ENTRENAMIENTO\n","epoch = 0  # INICIALIZAMOS CONTADOR DE EPOCAS"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7_wXRs4xxTjw"},"source":["while (epoch < MAX_EPOCHS) and (counter < 20):\n","    \n","    #------------\n","    # TRAIN\n","    #------------\n","    trn_loss, model = train_step(model, train_dataloader, loss_criterion, device)\n","    \n","    trn_loss, trn_acc = predict_step(model, train_dataloader, loss_criterion, device)  # TRAIN EVALUATION\n","    val_loss, val_acc = predict_step(model, val_dataloader, loss_criterion, device)  # VALIDATION EVALUATION\n","    \n","    measures['trn_loss'].append(trn_loss)\n","    measures['trn_acc'].append(trn_acc)\n","    \n","    measures['val_loss'].append(val_loss)\n","    measures['val_acc'].append(val_acc)\n","    \n","\n","    #=================================\n","    if (val_loss < best_loss):\n","        \n","        # Actualizo best_loss\n","        best_loss = val_loss\n","        best_epoch = epoch\n","        \n","        # Guardo mejor modelo\n","        best_model = model.state_dict()\n","        counter = 0\n","    \n","    else:\n","        counter += 1\n","    #=================================\n","\n","    if (epoch%10) == 0:\n","        print(f'Epoch {epoch}: trn_loss: {trn_loss:.5}\\t val_loss: {val_loss:.5}\\t trn_acc: {trn_acc}\\t val_acc: {val_acc}\\t counter: {counter}')\n","    \n","    # Avanzo 1 epoca\n","    epoch += 1\n","\n","\n","print(f'Best model:\\n\\nepoch: {best_epoch}\\nloss: {best_loss:.5}')\n","\n","# GUARDO MEJOR MODELO\n","torch.save(best_model, 'best_model_pytorch.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YD8cieUWRk0A"},"source":["fig, ax = plt.subplots(1,2,figsize=(22,6))\n","\n","ax[0].plot(measures['trn_loss'], 'C2', label='trn')\n","ax[0].plot(measures['val_loss'], 'C3', label='val')\n","ax[0].set_title('Loss')\n","ax[0].set_xlabel('epochs')\n","ax[0].set_ylabel('MSE')\n","ax[0].grid(True)\n","ax[0].legend()\n","\n","ax[1].plot(measures['trn_acc'], 'C2', label='trn')\n","ax[1].plot(measures['val_acc'], 'C3', label='val')\n","ax[1].set_title('Accuracy')\n","ax[1].set_xlabel('epochs')\n","ax[1].set_ylabel('Acc')\n","ax[1].grid(True)\n","ax[1].legend();"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yhU3HqwbY-P_"},"source":["### PREDICCIONES EN TEST"]},{"cell_type":"code","metadata":{"id":"7NPrISJgY-QA"},"source":["model = MLP_desglosado()\n","#model = MLP_bloque()\n","\n","model.to(device)\n","model.load_state_dict(best_model)\n","\n","tst_loss, tst_acc = predict_step(model, test_dataloader, loss_criterion, device)  # TEST EVALUATION\n","\n","print(f'\\nAcc: {tst_acc:.4}\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xmOUGNho7LvI"},"source":["## Dibujo patrones clasificados"]},{"cell_type":"code","metadata":{"id":"EFhOCe6y7xES"},"source":["#------------------\n","# UMBRAL\n","#------------------\n","umbral = 0.5\n","\n","#-------------------------------------\n","\n","TRAIN = {'X': None,\n","         'clase': []}\n","\n","Y = torch.tensor([])\n","Yp = torch.tensor([])\n","\n","for idx,(X,y) in enumerate(train_dataloader):\n","    \n","    if TRAIN['X'] is not None:\n","      TRAIN['X'] = np.vstack((TRAIN['X'], X.numpy()))  # Guardo patrones\n","    else:\n","      TRAIN['X'] = X.numpy()\n","\n","    Y = torch.hstack( (Y,y.flatten()) )\n","    \n","    X = X.to(device)\n","    y = y.to(device)\n","    y_pred = model(X)\n","    Yp = torch.hstack( (Yp, y_pred.cpu().squeeze()) )\n","\n","Yp[Yp<umbral] = 0\n","Yp[Yp >= umbral] = 1\n","\n","Yp[Yp!=Y] = -1\n","\n","TRAIN['clase'] = Yp.detach().cpu().numpy()\n","\n","#-------------------------------------\n","\n","VAL = {'X': None,\n","       'clase': []}\n","\n","Y = torch.tensor([])\n","Yp = torch.tensor([])\n","\n","for idx,(X,y) in enumerate(val_dataloader):\n","    \n","    if VAL['X'] is not None:\n","      VAL['X'] = np.vstack((VAL['X'], X.numpy()))  # Guardo patrones\n","    else:\n","      VAL['X'] = X.numpy()\n","\n","    Y = torch.hstack( (Y,y.flatten()) )\n","    \n","    X = X.to(device)\n","    y = y.to(device)\n","    y_pred = model(X)\n","    Yp = torch.hstack( (Yp,y_pred.cpu().squeeze()) )\n","\n","Yp[Yp<umbral] = 0\n","Yp[Yp >= umbral] = 1\n","Yp[Yp!=Y] = -1\n","\n","VAL['clase'] = Yp.detach().cpu().numpy()\n","\n","#-------------------------------------\n","\n","TEST = {'X': None,\n","         'clase': []}\n","\n","Y = torch.tensor([])\n","Yp = torch.tensor([])\n","\n","for idx,(X,y) in enumerate(test_dataloader):\n","    \n","    if TEST['X'] is not None:\n","      TEST['X'] = np.vstack((TEST['X'], X.numpy()))  # Guardo patrones\n","    else:\n","      TEST['X'] = X.numpy()\n","\n","    Y = torch.hstack( (Y,y.flatten()) )\n","    \n","    X = X.to(device)\n","    y = y.to(device)\n","    y_pred = model(X)\n","    Yp = torch.hstack( (Yp,y_pred.cpu().squeeze()) )\n","\n","Yp[Yp<umbral] = 0\n","Yp[Yp >= umbral] = 1\n","Yp[Yp!=Y] = -1\n","\n","TEST['clase'] = Yp.detach().cpu().numpy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"stQn2_BD7LAF"},"source":["fig, ax = plt.subplots(1,3,figsize=(24,8))\n","\n","# TRAIN\n","ax[0].scatter(TRAIN['X'][TRAIN['clase']==0,0],\n","              TRAIN['X'][TRAIN['clase']==0,1], 30, 'b', label='Clase 0')\n","\n","ax[0].scatter(TRAIN['X'][TRAIN['clase']==1,0],\n","              TRAIN['X'][TRAIN['clase']==1,1], 30, 'y', label='Clase 1')\n","\n","ax[0].scatter(TRAIN['X'][TRAIN['clase']==-1,0],\n","              TRAIN['X'][TRAIN['clase']==-1,1], 30, 'r', marker='s', label='Error')\n","\n","ax[0].set_title('Train data', fontsize=16)\n","ax[0].set_xlabel('$X_{1}$', fontsize=14)\n","ax[0].set_ylabel('$X_{2}$', fontsize=14)\n","ax[0].set_xlim([-0.05, 1.05])\n","ax[0].set_ylim([-0.05, 1.05])\n","ax[0].grid(True)\n","value = (TRAIN['clase'] != -1).sum()/TRAIN['clase'].shape[0]\n","ax[0].text(0.8, 0, f'Acc: {value:.3}', bbox=dict(facecolor='grey', alpha=0.25), fontsize=12)\n","ax[0].legend(loc='best')\n","\n","\n","# VALIDATION\n","ax[1].scatter(VAL['X'][VAL['clase']==0,0],\n","              VAL['X'][VAL['clase']==0,1], 30, 'b', label='Clase 0')\n","\n","ax[1].scatter(VAL['X'][VAL['clase']==1,0],\n","              VAL['X'][VAL['clase']==1,1], 30, 'y', label='Clase 1')\n","\n","ax[1].scatter(VAL['X'][VAL['clase']==-1,0],\n","              VAL['X'][VAL['clase']==-1,1], 30, 'r', marker='s', label='Error')\n","\n","ax[1].set_title('Validation data', fontsize=16)\n","ax[1].set_xlabel('$X_{1}$', fontsize=14)\n","ax[1].set_ylabel('$X_{2}$', fontsize=14)\n","ax[1].set_xlim([-0.05, 1.05])\n","ax[1].set_ylim([-0.05, 1.05])\n","ax[1].grid(True)\n","value = (VAL['clase'] != -1).sum()/VAL['clase'].shape[0]\n","ax[1].text(0.8, 0, f'Acc: {value:.3}', bbox=dict(facecolor='grey', alpha=0.25), fontsize=12)\n","ax[1].legend(loc='best')\n","\n","\n","#TEST\n","ax[2].scatter(TEST['X'][TEST['clase']==0,0],\n","              TEST['X'][TEST['clase']==0,1], 30, 'b', label='Clase 0')\n","\n","ax[2].scatter(TEST['X'][TEST['clase']==1,0],\n","              TEST['X'][TEST['clase']==1,1], 30, 'y', label='Clase 1')\n","\n","ax[2].scatter(TEST['X'][TEST['clase']==-1,0],\n","              TEST['X'][TEST['clase']==-1,1], 50, 'r', marker='s', label='Error')\n","\n","ax[2].set_title('Test data', fontsize=16)\n","ax[2].set_xlabel('$X_{1}$', fontsize=14)\n","ax[2].set_ylabel('$X_{2}$', fontsize=14)\n","ax[2].set_xlim([-0.05, 1.05])\n","ax[2].set_ylim([-0.05, 1.05])\n","ax[2].grid(True)\n","value = (TEST['clase'] != -1).sum()/TEST['clase'].shape[0]\n","ax[2].text(0.8, 0, f'Acc: {value:.3}', bbox=dict(facecolor='grey', alpha=0.25), fontsize=12)\n","ax[2].legend(loc='best');"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"joR9tG8fxTj3"},"source":[""],"execution_count":null,"outputs":[]}]}